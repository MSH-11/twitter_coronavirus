# Coronavirus Twitter Analysis Project

## Project Overview
This project aims to analyze the spread of discussions related to the coronavirus on Twitter, particularly through the lens of geotagged tweets from the year 2020. Utilizing approximately 1.1 billion tweets, the analysis focuses on the frequency and geographical distribution of specific hashtags related to the pandemic.

## Objectives
- **Handle large-scale datasets**: The project works with over a billion tweets, requiring efficient data processing and management techniques.
- **Process multilingual text**: Tweets are in various languages, and the analysis accounts for this diversity.
- **Implement MapReduce**: Employ the MapReduce paradigm for parallel processing of data to optimize performance.

## Methodology
- **Map**: Each day's worth of tweets is processed to count hashtag occurrences by language and country.
- **Reduce**: Daily counts are aggregated to provide a comprehensive view across the entire year.
- **Visualize**: Results are visualized using bar graphs and line plots to depict trends and distributions.

## Results
The project resulted in the creation of several visual representations of the data:
- A bar graph showing the frequency of `#coronavirus` by country.
- A bar graph displaying the frequency of `#coronavirus` by language.
- A bar graph for the hashtag `#코로나바이러스` by country.
- A bar graph for `#코로나바이러스` by language.
- A line plot that tracks the usage of specified hashtags over the course of the year.

Below are the visualizations generated by the `visualize.py` script:

![Coronavirus by Country](%23coronavirus_country.png)
![Coronavirus by Language](%23coronavirus_language.png)
![코로나바이러스 by Country](%23코로나바이러스_country.png)
![코로나바이러스 by Language](%23코로나바이러스_language.png)

Additionally, an `alternative_reduce.py` script was developed to create a line plot for multiple hashtags over the year:

![Hashtag Trends Over the Year](trends_coronavirus_코로나바이러스_covid-19.png)

## Conclusion
This project successfully demonstrates the ability to work with massive, multilingual datasets and to apply parallel processing techniques effectively. The insights gained from this analysis could be valuable for understanding the global conversation around significant events like the coronavirus pandemic.

